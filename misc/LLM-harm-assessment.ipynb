{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import os\n",
    "import pandas as pd \n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory to pull API keys, which isn't always in the directory you work in. \n",
    "%cd \"/Users/stevenmesquiti/Desktop/Working with Dani/My-climate-stories\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in api key for open ai. please make sure you do not store it in the script and use an .env file. \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key  = os.getenv('openai_api_key')\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-4-1106-preview\"): #you can use other models if you wish, but please be aware of their costs and limitations\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output i want this model to be very consistent with what it does \n",
    "        response_format={ \"type\": \"json_object\" }\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in csv \n",
    "df = pd.read_csv(\"/Users/stevenmesquiti/Box Sync/CurrentProjects_Penn/LP2/within_person_intervention/data/study_2-harm_audit.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pID.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all text values into a single row grouped by 'pID'\n",
    "df_grouped = df.groupby('pID')['text'].agg(lambda x: ' '.join(x)).reset_index()\n",
    "df_grouped = df_grouped.rename(columns={'text': 'concatenated_text'})\n",
    "df_grouped.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df_grouped.concatenated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of absolute words \n",
    "word_list = [\n",
    "    \"Absolutely\",\n",
    "    \"All\",\n",
    "    \"Always\",\n",
    "    \"Angry\",\n",
    "    \"Commit\",\n",
    "    \"Complete(ly)\",\n",
    "    \"Constant(ly)\",\n",
    "    \"Dead\",\n",
    "    \"Definitely\",\n",
    "    \"Entire\",\n",
    "    \"Ever\",\n",
    "    \"Every\",\n",
    "    \"Everyone\",\n",
    "    \"Everything\",\n",
    "    \"Fight(ing)\",\n",
    "    \"Fought\",\n",
    "    \"Full\",\n",
    "    \"Hopeless\",\n",
    "    \"Hungry\",\n",
    "    \"Life\",\n",
    "    \"Must\",\n",
    "    \"Never\",\n",
    "    \"Nothing\"\n",
    "]\n",
    "\n",
    "high_risk = [\n",
    "\"Better off dead\",\n",
    "\"Cut myself\",\n",
    "\"End my life\",\n",
    "\"Hang myself\",\n",
    "\"Hung myself\",\n",
    "\"Commit abuse\",\n",
    "\"Commit murder\",\n",
    "\"Commit rape\",\n",
    "\"Commit suicide\",\n",
    "\"Die by suicide\",\n",
    "\"Harm myself\",\n",
    "\"Hurt myself\",\n",
    "\"Kill myself\",\n",
    "\"Killed myself\",\n",
    "\"Kills myself\",\n",
    "\"Killing\",\n",
    "\"Kill\",\n",
    "\"Never wake up\",\n",
    "\"Never woke up\",\n",
    "\"Nothing matters\",\n",
    "\"Plan to die\",\n",
    "\"Self-harm\",\n",
    "\"Self-injury\",\n",
    "\"Sewerslide\",\n",
    "\"Suicidal\",\n",
    "\"Suicide\",\n",
    "\"Take my life\",\n",
    "\"Takes my life\",\n",
    "\"To be dead\",\n",
    "\"Unalive\",\n",
    "\"Want death\",\n",
    "\"Want to die\",\n",
    "\"Wanted death\",\n",
    "\"Wanted to die\",\n",
    "\"Wants death\",\n",
    "\"Wants to die\",\n",
    "\"Want to\",\n",
    "\"Will die\",\n",
    "\"Wish dead\"\n",
    "]\n",
    "\n",
    "low_risk = [\n",
    "\"Abuse(d)\",\n",
    "\"Beat/Beaten\",\n",
    "\"Bleed\",\n",
    "\"Die\",\n",
    "\"Died\",\n",
    "\"Dies\",\n",
    "\"Choke(d)\",\n",
    "\"Cut\",\n",
    "\"Gun\",\n",
    "\"Hate\",\n",
    "\"Hit\",\n",
    "\"Knife\",\n",
    "\"Murder\",\n",
    "\"Hurt\",\n",
    "\"Kick(ed)\",\n",
    "\"Punch(ed)\",\n",
    "\"Rape(d)\",\n",
    "\"Shoot\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = {}  # Create an empty dictionary to store the responses\n",
    "\n",
    "# this will try and catch all the errors that you may encounter with the API. \n",
    "#dont be surprised if you get rate limited super fast. that's ok, just be patient with the script\n",
    "#this may take a few hours to run \n",
    "\n",
    "def get_response(prompt):\n",
    "    try:\n",
    "        response = get_completion(prompt)\n",
    "        return response\n",
    "    except openai.error.RateLimitError as e:\n",
    "        retry_time = e.retry_after if hasattr(e, 'retry_after') else 30\n",
    "        print(f\"Rate limit exceeded. Retrying in {retry_time} seconds...\")\n",
    "        time.sleep(retry_time)\n",
    "        return get_response(prompt)\n",
    "    except openai.error.APIError as e:\n",
    "        retry_time = e.retry_after if hasattr(e, 'retry_after') else 30\n",
    "        print(f\"API error occurred. Retrying in {retry_time} seconds...\")\n",
    "        time.sleep(retry_time)\n",
    "        return get_response(prompt)\n",
    "    except openai.error.ServiceUnavailableError as e:\n",
    "        retry_time = 10  # Adjust the retry time as needed\n",
    "        print(f\"Service is unavailable. Retrying in {retry_time} seconds...\")\n",
    "        time.sleep(retry_time)\n",
    "        return get_response(prompt)\n",
    "    except openai.error.Timeout as e:\n",
    "        retry_time = 10  # Adjust the retry time as needed\n",
    "        print(f\"Request timed out: {e}. Retrying in {retry_time} seconds...\")\n",
    "        time.sleep(retry_time)\n",
    "        return get_response(prompt)\n",
    "    except OSError as e:\n",
    "        if isinstance(e, tuple) and len(e) == 2 and isinstance(e[1], OSError):\n",
    "            retry_time = 10  # Adjust the retry time as needed\n",
    "            print(f\"Connection error occurred: {e}. Retrying in {retry_time} seconds...\")\n",
    "            time.sleep(retry_time)\n",
    "            return get_response(prompt)\n",
    "        else:\n",
    "            retry_time = 10  # Adjust the retry time as needed\n",
    "            print(f\"Connection error occurred: {e}. Retrying in {retry_time} seconds...\")\n",
    "            time.sleep(retry_time)\n",
    "            raise e\n",
    "\n",
    "for i in tqdm(range(len(inputs))):\n",
    "    prompt = f\"\"\"\n",
    "Your task is to review a transcript for the following qualities \n",
    "\n",
    "- high priority indicators of possible risk, that mention any of the following (note context and rule out statements with negators (e.g., “I never want to end my life.”). Here are examples {\", \".join(high_risk)}. If none of these are present please respond with Not present.\\ \n",
    "- medium priority indicators of possible risk; note any noun or pronoun paired with words in this list (e.g., “Hate my mother”) (note context and rule out any statements with negators (e.g., “I would never shoot someone.”) Here are examples {\", \".join(low_risk)}.  If none of these are present please respond with Not present. \\ \n",
    "- indicate the frequency of words in a piece of text . Answer only with a number to indicate the number of times a word occurs in a piece of text. Here are the words {\", \".join(word_list)} \\ \n",
    "-  Provide a 50 word or less summary of what they talked about in their transcripts\n",
    "\n",
    "Output a single JSON object with information:\n",
    "Presence of High priority indicators in variable called High Priority \\ \n",
    "Presence of Medium priority indicators in variable called Medium Priority \\ \n",
    "Each word as a variable. Answer only with a number indicate the number of times a word occurs in a piece of text \\  \n",
    "Provide a 50 word or less summary of what they talked about in a Variable called Summary\n",
    "      \n",
    "Text: ```{inputs[i]}```\n",
    "\"\"\"\n",
    "    response = get_response(prompt)\n",
    "    responses[f\"{i+1}\"] = response  # Save the response in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in responses.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list\n",
    "all_responses = []\n",
    "\n",
    "# Process responses and populate all_responses\n",
    "for key in responses:\n",
    "    response_data = responses[key]\n",
    "    \n",
    "    # Find the start and end index of the JSON object\n",
    "    start_index = response_data.find('{')\n",
    "    end_index = response_data.rfind('}') + 1\n",
    "\n",
    "    # Extract the JSON object from the string\n",
    "    json_data = response_data[start_index:end_index]\n",
    "\n",
    "    try:\n",
    "        temp = json.loads(json_data)\n",
    "        all_responses.append(temp)\n",
    "\n",
    "        print(f\"Response: {key}\")\n",
    "        for key2 in temp:\n",
    "            print(f\"{key2}: value - {temp[key2]}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON for response {key}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(all_responses)\n",
    "summary.pID = df_grouped.pID\n",
    "# Print the DataFrame\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv('/Users/stevenmesquiti/Downloads/participant_harm_audit_summary_study2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
