{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm  # use this for general progress bars (works in console & notebooks)\n",
    "from openai import OpenAI, RateLimitError, APIError, APITimeoutError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"/Users/sm9518/Desktop/Article-Summarizer/.env\") # where i keep my API key... \n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"API Key loaded successfully!\\n:)\")\n",
    "else:\n",
    "    raise ValueError(\"API Key not found.\\nMake sure it is set in the .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/sm9518/Library/CloudStorage/Box-Box/LP2/well-being-prediction/data/Prolific_wellbeing-prediction-text-long.csv',index_col=0)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.sample(frac=frac, random_state=SEED) #randomly sample 300 comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters so we know what we're working with\n",
    "#model=\"gpt-3.5-turbo-1106\" # set model\n",
    "model='gpt-4'\n",
    "temperature=0 # set temp \n",
    "input_column = 'SWLS-Text' \n",
    "#input_column = 'Autonomy-Text'\n",
    "# create index of the text values... \n",
    "input = df[input_column].tolist()\n",
    "def get_completion(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def get_response(prompt):\n",
    "    try:\n",
    "        response = get_completion(prompt)\n",
    "        return response\n",
    "    except RateLimitError as e:\n",
    "        retry_time = e.retry_after if hasattr(e, 'retry_after') else 30\n",
    "        print(f\"Rate limit exceeded. Retrying in {retry_time} seconds...\")\n",
    "        time.sleep(retry_time)\n",
    "        return get_response(prompt)\n",
    "    except APIError as e:\n",
    "        retry_time = 30\n",
    "        print(f\"API error occurred. Retrying in {retry_time} seconds...\")\n",
    "        time.sleep(retry_time)\n",
    "        return get_response(prompt)\n",
    "    except APITimeoutError as e:\n",
    "        retry_time = 10\n",
    "        print(f\"Request timed out: {e}. Retrying in {retry_time} seconds...\")\n",
    "        time.sleep(retry_time)\n",
    "        return get_response(prompt)\n",
    "    except Exception as e:\n",
    "        retry_time = 10\n",
    "        print(f\"An error occurred: {e}. Retrying in {retry_time} seconds...\")\n",
    "        time.sleep(retry_time)\n",
    "        return get_response(prompt)\n",
    "\n",
    "# Initialize an empty dictionary to store responses\n",
    "responses = {}\n",
    "\n",
    "# Verify input contents\n",
    "print(f\"Total number of inputs: {len(input)}\")\n",
    "print(f\"Number of unique inputs: {len(set(input))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'input' is your list of text inputs\n",
    "for i, text in enumerate(tqdm(input)):\n",
    "    prompt = f\"\"\"\n",
    "    Your task is to evaluate the following piece of text along a 7-point scale (where 1 = not at all and 7 = a great deal) for each of the following well-being dimensions:\n",
    "\n",
    "    Self-acceptance\n",
    "    To what degree does the text reflect a positive attitude toward the self, including acknowledgment and acceptance of both strengths and weaknesses, and positive feelings about the past? \n",
    "\n",
    "    Positive relations with others\n",
    "    To what degree does the text convey warm, satisfying, or trusting relationships with others, empathy, affection, or concern for othersâ€™ welfare?\n",
    "\n",
    "    Autonomy\n",
    "    To what degree does the text suggest self-determination, independence, resistance to social pressures, or behavior guided by personal standards?\n",
    "\n",
    "    Environmental mastery\n",
    "    To what degree does the text indicate competence in managing life and environment, including the ability to navigate external demands or create favorable contexts?\n",
    "\n",
    "    Purpose in life\n",
    "    To what degree does the text suggest a sense of direction, meaningful goals, or beliefs that give life purpose?\n",
    "\n",
    "    Personal growth\n",
    "    To what degree does the text reflect openness to new experiences, personal development, or a sense of realizing potential and evolving as a person?\n",
    "\n",
    "    Satisfaction with life\n",
    "    To what degree does the text express a global assessment of life satisfaction or overall contentment with one's life circumstances?\n",
    "\n",
    "    Output your answer as a single JSON object with keys for each dimension (use these exact names: \"Self_acceptance\", \"Positive_relations\", \"Autonomy\", \"Environmental_mastery\", \"Purpose_in_life\", \"Personal_growth\",\"Satisfaction_with_life\").\n",
    "\n",
    "    Text: ```{input[i]}```\n",
    "    \"\"\"\n",
    "    response = get_response(prompt)\n",
    "    try:\n",
    "        # Attempt to parse the response as JSON\n",
    "        json_response = json.loads(response)\n",
    "        responses[f\"{i+1}\"] = json_response\n",
    "    except json.JSONDecodeError:\n",
    "        # If parsing fails, store the raw response\n",
    "        responses[f\"{i+1}\"] = response\n",
    "\n",
    "# After the loop, save the responses to a file\n",
    "with open('gpt_responses.json', 'w') as f:\n",
    "    json.dump(responses, f, indent=2)\n",
    "\n",
    "print(\"gpt_responses.json saved successfully.\")\n",
    "\n",
    "# Print the first 10 responses\n",
    "for i in range(1, min(11, len(responses) + 1)):\n",
    "    print(f\"{i}: {responses.get(str(i), 'No response')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list\n",
    "all_responses = []\n",
    "\n",
    "# Process responses and populate all_responses\n",
    "for key in responses:\n",
    "    temp = responses[key]  \n",
    "    all_responses.append(temp)\n",
    "\n",
    "    print(f\"Response: {key}\")\n",
    "    for key2 in temp:\n",
    "        print(f\"{key2}: value - {temp[key2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = input_column.split('-')[0]  # Extracts 'SWLS'\n",
    "prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(all_responses)\n",
    "scores_aligned = scores.reset_index(drop=True)\n",
    "column_map = {\n",
    "    \"Self_acceptance\":         f\"{prefix}_SelfAcceptance_{model}\",\n",
    "    \"Positive_relations\":      f\"{prefix}_PositiveRelations_{model}\",\n",
    "    \"Autonomy\":                f\"{prefix}_Autonomy_{model}\",\n",
    "    \"Environmental_mastery\":   f\"{prefix}_EnvironmentalMastery_{model}\",\n",
    "    \"Purpose_in_life\":         f\"{prefix}_PurposeInLife_{model}\",\n",
    "    \"Personal_growth\":         f\"{prefix}_PersonalGrowth_{model}\",\n",
    "    \"Satisfaction_with_life\":  f\"{prefix}_SWLS_{model}\"\n",
    "}\n",
    "scores_aligned = scores_aligned.rename(columns=column_map)\n",
    "df = df.reset_index(drop=True)\n",
    "for col in scores_aligned.columns:\n",
    "    df[col] = pd.to_numeric(scores_aligned[col], errors='coerce')\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpt_cols = [\n",
    "#'Autonomy_SelfAcceptance_gpt-3.5-turbo-1106',\n",
    "#'Autonomy_PositiveRelations_gpt-3.5-turbo-1106',\n",
    "#'Autonomy_Autonomy_gpt-3.5-turbo-1106',\n",
    "#'Autonomy_EnvironmentalMastery_gpt-3.5-turbo-1106',\n",
    "#'Autonomy_PurposeInLife_gpt-3.5-turbo-1106',\n",
    "#'Autonomy_PersonalGrowth_gpt-3.5-turbo-1106',\n",
    "#'Autonomy_SWLS_gpt-3.5-turbo-1106']\n",
    "\n",
    "gpt_cols = [ 'SWLS_SelfAcceptance_gpt-4','SWLS_PositiveRelations_gpt-4', 'SWLS_Autonomy_gpt-4','SWLS_EnvironmentalMastery_gpt-4', 'SWLS_PurposeInLife_gpt-4','SWLS_PersonalGrowth_gpt-4', 'SWLS_SWLS_gpt-4']\n",
    "\n",
    "# List of PWB columns\n",
    "pwb_cols = [\n",
    "    'PWB autonomy',\n",
    "    'PWB environmental_mastery',\n",
    "    'PWB mean',\n",
    "    'PWB personal_growth',\n",
    "    'PWB positive_relations',\n",
    "    'PWB purpose',\n",
    "    'PWB self_acceptance',\n",
    "    'SWLS mean'\n",
    "]\n",
    "\n",
    "# Subset the dataframe to relevant columns and drop rows with missing data\n",
    "df_corr = df[gpt_cols + pwb_cols].dropna()\n",
    "\n",
    "# Calculate correlation matrix between GPT and PWB columns\n",
    "corr_matrix = df_corr[gpt_cols].corrwith(df_corr[pwb_cols], axis=0)\n",
    "\n",
    "# Alternatively, compute full pairwise correlations between GPT and PWB columns\n",
    "corr_full = df_corr[gpt_cols + pwb_cols].corr().loc[gpt_cols, pwb_cols]\n",
    "\n",
    "print(\"Pairwise correlations between GPT and Well-being columns:\")\n",
    "print(corr_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"/Users/sm9518/Desktop/LP2-wellbeing-prediction/data/GPT/WBP-{input_column}-GPT-{model}-{temperature}-scores.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
